{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([90000]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import scipy.stats as sps\n",
    "import numpy as np\n",
    "import os.path\n",
    "import time\n",
    "\n",
    "import dgl\n",
    "from dgl.data.utils import download, extract_archive, get_download_dir\n",
    "\n",
    "import rdkit\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import MolFromSmiles, MolToSmiles\n",
    "from rdkit.Chem import rdmolops\n",
    "from bo import sascorer\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "from torch.distributions import constraints, transform_to\n",
    "\n",
    "from jtnn import *\n",
    "\n",
    "\n",
    "# from optparse import OptionParser\n",
    "import argparse\n",
    "\n",
    "torch.backends.cudnn.enabled=True\n",
    "\n",
    "lg = rdkit.RDLogger.logger()\n",
    "lg.setLevel(rdkit.RDLogger.CRITICAL)\n",
    "\n",
    "\n",
    "# We define the functions used to load and save objects\n",
    "def save_object(obj, filename):\n",
    "    result = pickle.dumps(obj)\n",
    "    with gzip.GzipFile(filename, 'wb') as dest: dest.write(result)\n",
    "    dest.close()\n",
    "\n",
    "\n",
    "def load_object(filename):\n",
    "    with gzip.GzipFile(filename, 'rb') as source: result = source.read()\n",
    "    ret = pickle.loads(result)\n",
    "    source.close()\n",
    "    return ret\n",
    "\n",
    "\n",
    "# parser = OptionParser()\n",
    "\"\"\"\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-v\", \"--vocab\", dest=\"vocab_path\", default=\"/home/ubuntu/ASAIL/jtnn_bo/jtnn/vocab.txt\")\n",
    "parser.add_argument(\"-m\", \"--model\", dest=\"model_path\", required=True)\n",
    "parser.add_argument(\"-o\", \"--save_dir\", dest=\"save_dir\", required=True)\n",
    "parser.add_argument(\"-n\", \"--n_train\", dest=\"training_num\", default=500)\n",
    "parser.add_argument(\"-i\", \"--n_ind\", dest=\"inducing_num\", default=500)\n",
    "parser.add_argument(\"-w\", \"--hidden\", dest=\"hidden_size\", default=200)\n",
    "parser.add_argument(\"-l\", \"--latent\", dest=\"latent_size\", default=56)\n",
    "parser.add_argument(\"-d\", \"--depth\", dest=\"depth\", default=3)\n",
    "parser.add_argument(\"-r\", \"--seed\", dest=\"random_seed\", default=19)\n",
    "parser.add_argument(\"-e\", \"--evaluate\", dest=\"eval\", default=False)\n",
    "\"\"\"\n",
    "\n",
    "vocab_path = \"/home/ubuntu/ASAIL/jtnn_bo/jtnn/vocab.txt\"\n",
    "model_path = \"model.iter-0-1500\"\n",
    "save_dir = \"result/\"\n",
    "hidden_size = 200\n",
    "latent_size = 56\n",
    "depth = 3\n",
    "random_seed = 1\n",
    "training_num = 100000\n",
    "inducing_num = 1000\n",
    "#eval = \"False\"\n",
    "eval = True\n",
    "\n",
    "\n",
    "# We load the random seed\n",
    "np.random.seed(int(random_seed))\n",
    "\n",
    "# We load the data (y is minued!)\n",
    "kkk = int(training_num)\n",
    "M = int(inducing_num)\n",
    "X = np.loadtxt('./bo/latent_features2.txt')[:kkk]\n",
    "y = -np.loadtxt('./bo/targets2.txt')[:kkk]\n",
    "y = y.reshape((-1, 1))\n",
    "logP_values = np.loadtxt('./bo/logP_values2.txt')\n",
    "SA_scores = np.loadtxt('./bo/SA_scores2.txt')\n",
    "cycle_scores = np.loadtxt('./bo/cycle_scores2.txt')\n",
    "SA_scores_normalized = (np.array(SA_scores) - np.mean(SA_scores)) / np.std(SA_scores)\n",
    "logP_values_normalized = (np.array(logP_values) - np.mean(logP_values)) / np.std(logP_values)\n",
    "cycle_scores_normalized = (np.array(cycle_scores) - np.mean(cycle_scores)) / np.std(cycle_scores)\n",
    "#y = -logP_values\n",
    "#y = y[:kkk].reshape((-1, 1))\n",
    "#y = (np.array(y) - np.mean(y)) / np.std(y)\n",
    "\n",
    "\n",
    "device = \"cuda\"\n",
    "#device = \"cpu\"\n",
    "\n",
    "n = X.shape[0]\n",
    "\n",
    "permutation = np.random.choice(n, n, replace=False)\n",
    "\n",
    "X_train = X[permutation, :][0: np.int(np.round(0.9 * n)), :]\n",
    "X_test = X[permutation, :][np.int(np.round(0.9 * n)):, :]\n",
    "\n",
    "y_train = y[permutation][0: np.int(np.round(0.9 * n))]\n",
    "y_test = y[permutation][np.int(np.round(0.9 * n)):]\n",
    "\n",
    "y_train = y_train.transpose()\n",
    "y_test = y_test.transpose()\n",
    "\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float().to(device)\n",
    "y_train = torch.from_numpy(y_train).float().to(device)\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "\n",
    "# Train sparse Gaussian by gpytorch:\n",
    "\n",
    "import gpytorch\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel, InducingPointKernel\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "\n",
    "class GPRegressionModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = ConstantMean()\n",
    "        self.base_covar_module = ScaleKernel(RBFKernel())\n",
    "        self.covar_module = InducingPointKernel(self.base_covar_module, inducing_points=train_x[:M, :], likelihood=likelihood)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "    \n",
    "y_train, y_test = y_train.reshape(-1), y_test.reshape(-1)\n",
    "print(y_train.shape, y_test.shape)\n",
    "    \n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood().to(device)\n",
    "model = GPRegressionModel(X_train, y_train, likelihood).to(device)\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "#training_iterations = 200\n",
    "def train(training_iterations=100, optimizer=optimizer, X_train=X_train, y_train=y_train):\n",
    "    for i in range(training_iterations):\n",
    "        # Zero backprop gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Get output from model\n",
    "        output = model(X_train)\n",
    "        # Calc loss and backprop derivatives\n",
    "        loss = -mll(output, y_train)\n",
    "        loss.backward(retain_graph = True)\n",
    "        print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\n",
    "        optimizer.step()\n",
    "        #torch.cuda.empty_cache()\n",
    "if eval == \"False\":\n",
    "    with gpytorch.settings.use_toeplitz(True):\n",
    "        train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianLikelihood(\n",
       "  (quadrature): GaussHermiteQuadrature1D()\n",
       "  (noise_covar): HomoskedasticNoise(\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model \n",
    "\n",
    "state_dict = torch.load('result/SGPmodel_state.pth')\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "model = GPRegressionModel(X_train, y_train, likelihood)  # Create a new GP model\n",
    "model.load_state_dict(state_dict) \n",
    "model.to(device).eval()\n",
    "likelihood.to(device).eval()\n",
    "#with gpytorch.settings.max_preconditioner_size(10), torch.no_grad():\n",
    "#    with gpytorch.settings.use_toeplitz(False), gpytorch.settings.max_root_decomposition_size(30), gpytorch.settings.fast_pred_var():\n",
    "#        preds = model(X_test)\n",
    "#loss = -mll(preds, y_test)\n",
    "#print(\"Test mll:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function for BO\n",
    "from scipy.stats import norm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def update_posterior(X_new, Y_new, iter=10):\n",
    "\n",
    "    model.set_train_data(X_new, Y_new)\n",
    "    # optimize the GP hyperparameters using Adam with lr=0.005\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    train(training_iteration=iter, optimizer=optimizer)\n",
    "\n",
    "# Define Acquisition function\n",
    "# TODO: the original paper uses expected imporvement \n",
    "def lower_confidence_bound(x, kappa=2):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    mu, variance = model(x).mean, model(x).variance\n",
    "    sigma = variance.sqrt()\n",
    "    return mu - kappa * sigma\n",
    "\n",
    "def find_a_candidate(x_init, lb, ub):\n",
    "    # transform x to an unconstrained domain\n",
    "    constraint = constraints.interval(lb, ub)\n",
    "    #print(x_init)\n",
    "    unconstrained_x_init = transform_to(constraint).inv(x_init)\n",
    "    #print(unconstrained_x_init)\n",
    "    unconstrained_x = unconstrained_x_init.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # WARNING: this is a memory intensive optimizer\n",
    "    # TODO: Maybe try other gradient-based iterative methods\n",
    "    minimizer = optim.LBFGS([unconstrained_x], max_iter=10)\n",
    "\n",
    "    def closure():\n",
    "        minimizer.zero_grad()\n",
    "        x = transform_to(constraint)(unconstrained_x)\n",
    "        y = lower_confidence_bound(x)\n",
    "        #y = lower_confidence_bound(unconstrained_x)\n",
    "        #print(autograd.grad(y, unconstrained_x))\n",
    "        print(y)\n",
    "        autograd.backward(unconstrained_x, autograd.grad(y, unconstrained_x))\n",
    "        return y\n",
    "\n",
    "    minimizer.step(closure)\n",
    "    # after finding a candidate in the unconstrained domain,\n",
    "    # convert it back to original domain.\n",
    "    x = transform_to(constraint)(unconstrained_x)\n",
    "    return x.detach()\n",
    "\n",
    "def next_x(lb, ub, num_candidates_each_x=5, num_x=60):\n",
    "    lb = lb.to(device)\n",
    "    ub = ub.to(device)\n",
    "    found_x=[]\n",
    "    x_init = model.train_inputs[0][-1:].to(device)\n",
    "    for j in range(num_x):\n",
    "        candidates = []\n",
    "        values = []\n",
    "        for i in range(num_candidates_each_x):\n",
    "            x = find_a_candidate(x_init, lb.to(device), ub.to(device))\n",
    "            y = lower_confidence_bound(x)\n",
    "            #print(\"next x:\", x, x.shape)\n",
    "            #print(\"next y:\", y, y.shape)\n",
    "            candidates.append(x)\n",
    "            values.append(y)\n",
    "            x_init = x.new_empty(1,56).uniform_(0, 1).mul(ub-lb).add_(lb).to(device)\n",
    "            #print(\"next\",x_init)\n",
    "        argmin = torch.min(torch.cat(values), dim=0)[1].item()\n",
    "        found_x.append(candidates[argmin])\n",
    "        x_init=found_x[-1]\n",
    "    return found_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "lb = torch.min(X_train, dim = 0)[0]\n",
    "ub = torch.max(X_train, dim = 0)[0]\n",
    "xmin = next_x(lb,ub,5,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try gpytorch Bayesian optimization:\n",
    "# Define helper function for BO\n",
    "from scipy.stats import norm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def update_posterior(X_new, Y_new, iter=50):\n",
    "    #model.to(\"cuda\")\n",
    "    model.set_train_data(X_new, Y_new, strict = False)\n",
    "    # optimize the GP hyperparameters using Adam with lr=0.005\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    train(training_iterations=iter, optimizer=optimizer)\n",
    "\n",
    "# Define Acquisition function\n",
    "# TODO: the original paper uses expected imporvement \n",
    "def lower_confidence_bound(x, kappa=0.5):\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    #with gpytorch.settings.max_preconditioner_size(10), torch.no_grad():\n",
    "    #    with gpytorch.settings.use_toeplitz(False), gpytorch.settings.max_root_decomposition_size(30), gpytorch.settings.fast_pred_var():\n",
    "            #preds = model(x)\n",
    "    with gpytorch.settings.max_root_decomposition_size(30), gpytorch.settings.fast_pred_var():\n",
    "        preds = model(x)\n",
    "    mu, variance = preds.mean, preds.variance\n",
    "    sigma = variance.sqrt()\n",
    "    return mu - kappa * sigma\n",
    "\n",
    "def expected_improvement(x):\n",
    "    mu, variance = model(x, full_cov=False, noiseless=False)\n",
    "    x_sample = model.X\n",
    "    sigma = variance.sqrt()\n",
    "    mu_sample, v_sample = model(X_sample, full_cov=False, noiseless=False)\n",
    "    mu_sample_opt = torch.max(mu_sample)\n",
    "    imp = mu - mu_sample\n",
    "    z = imp / sigma\n",
    "    ei = F.relu(imp) + sigma * norm.pdf(z) - torch.abs(imp) * norm.cdf(z)\n",
    "    return ei\n",
    "        \n",
    "def find_a_candidate(x_init, lb, ub):\n",
    "\n",
    "    def acquisition_minimizer(x_init, iterations=100):\n",
    "        #x = x_init.clone().requires_grad_(True)\n",
    "        x = x_init.requires_grad_(True)\n",
    "        minimizer = optim.Adam([x], lr=0.01)\n",
    "        for i in range(iterations):\n",
    "            y = lower_confidence_bound(x)\n",
    "            #print(\"iteration - {}: lower_confidence_bound: {}\".format(i, y))\n",
    "            autograd.backward(x, autograd.grad(y, x, retain_graph = True, allow_unused = True), retain_graph=True)\n",
    "            #y.backward(retain_graph=True)\n",
    "            #print(x.grad)\n",
    "            minimizer.step()\n",
    "        return x\n",
    "    x = acquisition_minimizer(x_init)\n",
    " \n",
    "    print(\"minimizer finished\")\n",
    "    # after finding a candidate in the unconstrained domain,\n",
    "    # convert it back to original domain.\n",
    "    return x.detach()\n",
    "\n",
    "def next_x(lb, ub, num_candidates_each_x=5, num_x=60):\n",
    "    #device = \"cuda\"\n",
    "    #model.to(device)\n",
    "    #likelihood.to(device)\n",
    "    found_x=[]\n",
    "    lb = lb.to(device)\n",
    "    ub = ub.to(device)\n",
    "    x_init = model.train_inputs[0][-1:].to(device)\n",
    "    for j in range(num_x):\n",
    "        candidates = []\n",
    "        values = []\n",
    "        for i in range(num_candidates_each_x):\n",
    "            print(\"start finding candidate\")\n",
    "            x = find_a_candidate(x_init, lb, ub)\n",
    "            y = lower_confidence_bound(x)\n",
    "            print(y)\n",
    "            #print(\"next x:\", x, x.shape)\n",
    "            #print(\"next y:\", y, y.shape)\n",
    "            candidates.append(x)\n",
    "            values.append(y)\n",
    "            # require another random initialization\n",
    "            #x_init = x.new_empty(1,56).uniform_(0, 1).mul(ub-lb).add_(lb).to(\"cuda\")\n",
    "            x_init = x.new_empty(1,56).normal_(0, 1).to(\"cuda\")\n",
    "            #print(\"next\",x_init)\n",
    "        argmin = torch.min(torch.cat(values), dim=0)[1].item()\n",
    "        min_score = torch.min(torch.cat(values), dim=0)[0].item()\n",
    "        print(min_score)\n",
    "        found_x.append(candidates[argmin])\n",
    "        x_init=found_x[-1]\n",
    "    return found_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lb = torch.min(X_train, dim = 0)[0]\n",
    "ub = torch.max(X_train, dim = 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-9.4142], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-4.1175], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-5.9779], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-5.2321], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-5.0462], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "-9.414225578308105\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-9.4469], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-4.8421], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-6.6488], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-6.0341], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-4.6696], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "-9.44691276550293\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-9.4616], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-4.8432], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-5.9653], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-4.4777], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-4.8830], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "-9.461607933044434\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-9.4383], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-6.0502], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-5.3747], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-4.5820], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-4.5056], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "-9.43828296661377\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-9.3752], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-5.6857], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-6.4191], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-4.6764], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-6.1405], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "-9.375247955322266\n"
     ]
    }
   ],
   "source": [
    "xmin = next_x(lb,ub,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [x.strip(\"\\r\\n \") for x in open(vocab_path)]\n",
    "vocab = Vocab(vocab)\n",
    "JT_model = DGLJTNNVAE(vocab, hidden_size, latent_size, depth)\n",
    "JT_model.load_state_dict(torch.load(model_path))\n",
    "JT_model = cuda(JT_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-7.2157], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n",
      "minimizer finished\n",
      "tensor([-7.8597], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "start finding candidate\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 344.00 MiB (GPU 0; 15.75 GiB total capacity; 12.57 GiB already allocated; 312.88 MiB free; 1.70 GiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-abca8d711d5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mxmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xmin:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvalid_smiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-448f4e87216f>\u001b[0m in \u001b[0;36mnext_x\u001b[0;34m(lb, ub, num_candidates_each_x, num_x)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_candidates_each_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start finding candidate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_a_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlower_confidence_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-448f4e87216f>\u001b[0m in \u001b[0;36mfind_a_candidate\u001b[0;34m(x_init, lb, ub)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mminimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquisition_minimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"minimizer finished\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-448f4e87216f>\u001b[0m in \u001b[0;36macquisition_minimizer\u001b[0;34m(x_init, iterations)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mminimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlower_confidence_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;31m#print(\"iteration - {}: lower_confidence_bound: {}\".format(i, y))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_unused\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-448f4e87216f>\u001b[0m in \u001b[0;36mlower_confidence_bound\u001b[0;34m(x, kappa)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m#preds = model(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_root_decomposition_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_pred_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/gpytorch/models/exact_gp.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;31m# Make the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_eval_tolerance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0mpredictive_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictive_covar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexact_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;31m# Reshape predictive mean to match the appropriate event shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/gpytorch/models/exact_prediction_strategies.py\u001b[0m in \u001b[0;36mexact_prediction\u001b[0;34m(self, joint_mean, joint_covar)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         return (\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexact_predictive_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_train_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexact_predictive_covar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_test_covar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_train_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/gpytorch/models/exact_prediction_strategies.py\u001b[0m in \u001b[0;36mexact_predictive_mean\u001b[0;34m(self, test_mean, test_train_covar)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;31m# For efficiency - we can use addmv in the 2d case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtest_train_covar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelazify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_train_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;31m# In other cases - we'll use the standard infrastructure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36mdelazify\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1745\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1747\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"object of class {} cannot be made into a Tensor\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mcache_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0madd_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mcache_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0madd_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mevaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             res = self.kernel(\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             )\n\u001b[1;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_active_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/gpytorch/kernels/kernel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLazyEvaluatedKernelTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/gpytorch/kernels/inducing_point_kernel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, diag, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mcovar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_covariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/gpytorch/kernels/inducing_point_kernel.py\u001b[0m in \u001b[0;36m_get_covariance\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mk_ux2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelazify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minducing_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             covar = MatmulLazyTensor(\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mk_ux1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inducing_inv_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_ux2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inducing_inv_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             )\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 344.00 MiB (GPU 0; 15.75 GiB total capacity; 12.57 GiB already allocated; 312.88 MiB free; 1.70 GiB cached)"
     ]
    }
   ],
   "source": [
    "#BO 5 times\n",
    "max_iteration=5\n",
    "for iteration in range(max_iteration):\n",
    "\n",
    "    xmin = next_x(lb,ub,5,5)\n",
    "    print(\"xmin:\", len(xmin), xmin[0].shape)\n",
    "    valid_smiles=[]\n",
    "    scores=[]\n",
    "    real_scores = []\n",
    "    for x_new in xmin:\n",
    "        #model = DGLJTNNVAE(vocab, hidden_size, latent_size, depth)\n",
    "        #model.load_state_dict(torch.load(opts.model_path))\n",
    "        #model = cuda(model)\n",
    "        tree_vec, mol_vec = x_new.chunk(2,1)\n",
    "        #print(x_new.shape, tree_vec.shape, mol_vec.shape)\n",
    "        #print(x_new)\n",
    "        s=JT_model.decode(tree_vec, mol_vec)\n",
    "        if s is not None:\n",
    "            valid_smiles.append(s)\n",
    "\n",
    "            current_log_P_value = Descriptors.MolLogP(MolFromSmiles(s))\n",
    "            current_SA_score = -sascorer.calculateScore(MolFromSmiles(s))\n",
    "            cycle_list = nx.cycle_basis(nx.Graph(rdmolops.GetAdjacencyMatrix(MolFromSmiles(s))))\n",
    "            if len(cycle_list) == 0:\n",
    "                cycle_length = 0\n",
    "            else:\n",
    "                cycle_length = max([ len(j) for j in cycle_list ])\n",
    "            if cycle_length <= 6:\n",
    "                cycle_length = 0\n",
    "            else:\n",
    "                cycle_length = cycle_length - 6\n",
    "\n",
    "            current_cycle_score = -cycle_length\n",
    "\n",
    "            current_SA_score_normalized = (current_SA_score - np.mean(SA_scores)) / np.std(SA_scores)\n",
    "            current_log_P_value_normalized = (current_log_P_value - np.mean(logP_values)) / np.std(logP_values)\n",
    "            current_cycle_score_normalized = (current_cycle_score - np.mean(cycle_scores)) / np.std(cycle_scores)\n",
    "\n",
    "            score = current_SA_score_normalized + current_log_P_value_normalized + current_cycle_score_normalized\n",
    "            y_new=-score\n",
    "            scores.append(y_new)\n",
    "            real_scores.append(current_log_P_value + current_SA_score - current_cycle_score)\n",
    "            \n",
    "            #print(gpmodel.X.shape)\n",
    "            #print(x_new.shape)\n",
    "\n",
    "            X = torch.cat((model.train_inputs[0], x_new.to(\"cuda\")),0) # incorporate new evaluation\n",
    "\n",
    "            #print(torch.tensor(y_new).float())\n",
    "            print(model.train_targets.shape)\n",
    "            print(torch.tensor([y_new]).shape)\n",
    "            \n",
    "            y = torch.cat((model.train_targets, torch.tensor([y_new]).float().to(\"cuda\")),0)\n",
    "            \n",
    "            #print(y.shape)\n",
    "            #print(y.type())\n",
    "    if iteration < max_iteration-1:\n",
    "        update_posterior(X, y)\n",
    "        preds = model(X_train)\n",
    "        RMSE = np.sqrt(np.mean((preds.mean.numpy() - y_test.numpy())**2))\n",
    "        print(\"Train RMSE: \",RMSE)\n",
    "        preds = model(X_test)\n",
    "        RMSE = np.sqrt(np.mean((preds.mean.numpy() - y_test.numpy())**2))\n",
    "        print(\"Test RMSE: \",RMSE)\n",
    "    print(len(scores),\" new molecules are found. Iteration-\",iteration)\n",
    "    print(valid_smiles)\n",
    "    print(real_scores)\n",
    "    #save_object(valid_smiles, save_dir + \"/valid_smiles{}.txt\".format(iteration))\n",
    "    #save_object(scores, save_dir + \"/scores{}.txt\".format(iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdBase\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit import RDConfig\n",
    "import os\n",
    "#template = Chem.MolFromSmiles('c1nccc2n1ccc2')\n",
    "#AllChem.Compute2DCoords(template)\n",
    "ms = []\n",
    "for smile in valid_smiles:\n",
    "    ms.append(MolFromSmiles(smile))\n",
    "img = Draw.MolsToGridImage(ms[:5],molsPerRow=1,subImgSize=(300,300))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300 at 0x7F41CA51DBA8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "ms = []\n",
    "for x_new in xmin:\n",
    "    #model = DGLJTNNVAE(vocab, hidden_size, latent_size, depth)\n",
    "    #model.load_state_dict(torch.load(opts.model_path))\n",
    "    #model = cuda(model)\n",
    "    tree_vec, mol_vec = x_new.chunk(2,1)\n",
    "    #print(x_new.shape, tree_vec.shape, mol_vec.shape)\n",
    "    #print(x_new)\n",
    "    s=JT_model.decode(tree_vec, mol_vec)\n",
    "    if s is not None:\n",
    "        valid_smiles.append(s)\n",
    "        \n",
    "        current_log_P_value = Descriptors.MolLogP(MolFromSmiles(s))\n",
    "        current_SA_score = -sascorer.calculateScore(MolFromSmiles(s))\n",
    "        cycle_list = nx.cycle_basis(nx.Graph(rdmolops.GetAdjacencyMatrix(MolFromSmiles(s))))\n",
    "        if len(cycle_list) == 0:\n",
    "            cycle_length = 0\n",
    "        else:\n",
    "            cycle_length = max([ len(j) for j in cycle_list ])\n",
    "        if cycle_length <= 6:\n",
    "            cycle_length = 0\n",
    "        else:\n",
    "            cycle_length = cycle_length - 6\n",
    "\n",
    "        current_cycle_score = -cycle_length\n",
    "\n",
    "        current_SA_score_normalized = (current_SA_score - np.mean(SA_scores)) / np.std(SA_scores)\n",
    "        current_log_P_value_normalized = (current_log_P_value - np.mean(logP_values)) / np.std(logP_values)\n",
    "        current_cycle_score_normalized = (current_cycle_score - np.mean(cycle_scores)) / np.std(cycle_scores)\n",
    "\n",
    "        score = current_SA_score_normalized + current_log_P_value_normalized + current_cycle_score_normalized\n",
    "        y_new=-score\n",
    "        scores.append(y_new)\n",
    "        real_scores.append(current_log_P_value + current_SA_score - current_cycle_score)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
